{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchsize=128\n",
    "epoch_num=1000000\n",
    "learning_rate=0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(24),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.CenterCrop(24),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='~/eunbi', train=True, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=batchsize, shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='~/eunbi', train=False, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=batchsize, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ion()\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(4):\n",
    "    image, label = trainset[i]\n",
    "\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('#{}: {}'.format(i, classes[label]))\n",
    "    ax.axis('off')\n",
    "\n",
    "    image = image / 2 + 0.5     # unnormalize\n",
    "    npimage = image.numpy()\n",
    "    npimage = np.transpose(npimage, (1, 2, 0))\n",
    "    plt.imshow(npimage)\n",
    "    \n",
    "image = image.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py:24: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 3 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, stride=1, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(32, 10, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(10, 20, kernel_size=2)\n",
    "        self.conv4 = nn.Conv2d(20, 40, kernel_size=3)\n",
    "        self.conv5 = nn.Conv2d(40, 30, kernel_size=2)\n",
    "        self.mp = nn.MaxPool2d(2, padding=1, stride=1)\n",
    "        self.fc1 = nn.Linear(15870, 60)           # 500 can be changed\n",
    "        self.fc2 = nn.Linear(60, 30)\n",
    "        self.fc3 = nn.Linear(30, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = self.mp(F.relu(self.conv1(x)))\n",
    "        x = self.mp(F.relu(self.conv2(x)))\n",
    "        x = self.mp(F.relu(self.conv3(x)))\n",
    "        x = self.mp(F.relu(self.conv4(x)))\n",
    "        x = self.mp(F.relu(self.conv5(x)))\n",
    "        x = x.view(in_size, -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    net= nn.DataParallel(net)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs: 1, Mini Batch order: 0\n",
      "Number of epochs: 2, Mini Batch order: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2975:\n",
      "Process Process-2974:\n",
      "Process Process-2973:\n",
      "Process Process-2976:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 121, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 76, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 81, in to_tensor\n",
      "    img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/site-packages/torchvision/datasets/cifar.py\", line 121, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 423, in __call__\n",
      "    return F.crop(img, i, j, h, w)\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 299, in crop\n",
      "    return img.crop((j, i, j + w, i + h))\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/site-packages/PIL/Image.py\", line 1078, in crop\n",
      "    return self._new(self._crop(self.im, box))\n",
      "  File \"/home/tf_study/anaconda3/envs/cifar10/lib/python3.6/site-packages/PIL/Image.py\", line 552, in _new\n",
      "    new.info = self.info.copy()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-53ae3a89e290>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cifar10/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training the network\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for epoch in range(epoch_num):  \n",
    "        for i,(images, labels) in enumerate(trainloader):\n",
    "            images=images.to(device)\n",
    "            labels=labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #Forward Backward Optimize\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            if i%1000==0:\n",
    "                print('Number of epochs: %d, Mini Batch order: %d' %(epoch+1,i))\n",
    "                #torch.save(model,'./cifar_model.pkl')              \n",
    "else:\n",
    "    for epoch in range(epoch_num):  \n",
    "        for i, data in enumerate(trainloader,0):\n",
    "            inputs, labels = data \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #Forward Backward Optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "                # print statistics\n",
    "            if i%1000==0:\n",
    "                print('Number of epochs: %d, Per Batch: %d' %(epoch+1,i))\n",
    "                #torch.save(model,'./cifar_model.pkl')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test data\n",
    "\n",
    "with torch.no_grad():\n",
    "    num_correct = 0\n",
    "    total_data = 0\n",
    "    if torch.cuda.is_available():\n",
    "        for images, labels in testloader:\n",
    "            images=images.to(device)\n",
    "            labels=labels.to(device)\n",
    "            output = net(images)\n",
    "            _, expected = torch.max(output.data, 1)\n",
    "\n",
    "            total_data += labels.size(0)\n",
    "            num_correct += (expected == labels).sum().item()\n",
    "    else:\n",
    "        for data in testloader:\n",
    "            image, label=data\n",
    "            output = net(image)\n",
    "            _, expected = torch.max(output.data, 1)\n",
    "\n",
    "            total_data += label.size(0)\n",
    "            num_correct += (expected == label).sum().item()\n",
    "        \n",
    "print('Accuracy of the Data: %d %%' % (100 * num_correct / total_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #2 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-da16203bc086>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexpected\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cifar10/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-c997ffc37800>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0min_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cifar10/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cifar10/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #2 'weight'"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        \n",
    "        output = net(images).cuda()\n",
    "        _, expected = torch.max(output, 1)\n",
    "        c = (expected == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cifar10",
   "language": "python",
   "name": "cifar10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
